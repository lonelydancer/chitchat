#load model
vocab_path="ernie-1.0/vocab.txt"
config_path="ernie-1.0/ernie_config.json"
init_model="ernie-1.0/params"

#vocab_path="ernie-1.0/vocab.txt"
#config_path="ernie-1.0/ernie_config.json"
#init_model="checkpoints/epoch_0/"

#checkpoints='checkpoints_noise'
#for multi-turn dialog/qa
task_type="dialog"
role_type_size=3
turn_type_size=10

#input
#max_src_len=472
max_seq_len=256
max_src_len=216
max_tgt_len=40
tokenized_input="false"
continuous_position="true"
batch_size=8
#batch_size=2
in_tokens="false"

#decode
do_decode="true"
max_dec_len=32
#max_dec_len=10
#max_dec_len=3
beam_size=5
#beam_size=2
length_penalty=1.3
use_multi_gpu_test="true"

#train
epoch=10
weight_decay=0.01
label_smooth=0.0
hidden_dropout_prob=0.1
save_and_valid_by_epoch="true"
#lr
warmup_proportion=0.1
lr_scheduler="linear_warmup_decay"
learning_rate=1e-4
#noise
random_noise="false"
noise_prob=0.5

#dataset
data_path="./data/"
train_set="train.all"
#train_set="train.data"
#dev_set="dev.data"
dev_set="train.data"
pred_set="test.data"
do_train="true"
#do_train="false"
#do_val="true"
do_val="false"
do_test="false"
do_pred="true"
do_decode="true"

#evaluate
eval_script="sh ./eval/tasks/chitchat/eval.sh"
eval_mertrics="bleu_1,bleu_2,distinct_1,distinct_2"
